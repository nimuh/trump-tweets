{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Nima/anaconda/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import nltk\n",
    "import re\n",
    "from string import punctuation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gensim\n",
    "import json\n",
    "import pickle\n",
    "from nltk.util import ngrams\n",
    "#import pyLDAvis.gensim\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('tweets_at_trump.csv')\n",
    "tweets = tweets.drop(['Unnamed: 0'], axis=1)\n",
    "tweets = tweets.drop(['index'], axis=1)\n",
    "tweets = tweets.drop(['user'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "android    3112\n",
       "Other      2647\n",
       "iphone      591\n",
       "windows     289\n",
       "ipad        119\n",
       "web          76\n",
       "macos        50\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 5 artists>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutral = 0\n",
    "neg = 0\n",
    "pos = 0\n",
    "\n",
    "for t in tweets['sentiment_type']:\n",
    "    if t == 'NEUTRAL': \n",
    "        neutral += 1\n",
    "    elif t == 'NEGATIVE':\n",
    "        neg += 1\n",
    "    else:\n",
    "        pos += 1\n",
    "\n",
    "droid = 0\n",
    "apple = 0\n",
    "windows = 0\n",
    "web = 0\n",
    "other = 0\n",
    "for s in tweets['source']:\n",
    "    if s == 'android':\n",
    "        droid += 1\n",
    "    elif s == 'iphone' or s == 'ipad' or s == 'macos':\n",
    "        apple += 1\n",
    "    elif s == 'web':\n",
    "        web += 1\n",
    "    elif s == 'windows':\n",
    "        windows += 1\n",
    "    else:\n",
    "        other += 1\n",
    "\n",
    "source_counts = {'ANDROID': droid, 'APPLE': apple, 'WINDOWS': windows, 'WEB': web, 'OTHER': other}\n",
    "type_counts = {'NEGATIVE': neg, 'POSTIVE': pos, 'NEUTRAL': neutral}\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.ylabel('Number of Tweets')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.bar(list(type_counts.keys()), list(type_counts.values()), width=0.4)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.xlabel('Platforms')\n",
    "plt.bar(list(source_counts.keys()), list(source_counts.values()), width=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group the tweets by location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tweets are grouped by location and then each group's corresponding dataframe is added to a list. This list will be used to build an LDA model for each group of tweets to extract topics for each place individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets['zipcode'] = tweets.zipcode.astype('category')\n",
    "places = tweets['place'].unique()\n",
    "\n",
    "tweets_by_place = []\n",
    "df_by_place = tweets.groupby('place')\n",
    "\n",
    "for i in range(len(places)):\n",
    "    tweets_by_place.append(df_by_place.get_group(places[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tweets are then cleaned and removed of stop words. Each tweet is then converted to a bigram. The tokenized tweets are used as a dictionary and as a corpus for the LDA model implemented by Gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# This function will be used on each dataframe in tweets_by_place \n",
    "def lda(tweets, num_topics):\n",
    "    coherences = []\n",
    "    topic_num = []\n",
    "    en_stop = set(nltk.corpus.stopwords.words('english'))\n",
    "    tok_twts = []\n",
    "    n = 2\n",
    "    for tweet in tweets['tweet']:\n",
    "        tokens = nltk.tokenize.word_tokenize(tweet)\n",
    "        tokens = [token for token in tokens if token not in en_stop]\n",
    "        tokens = [token.lower() for token in tokens]\n",
    "        ngrams = zip(*[tokens[i:] for i in range(n)])\n",
    "        tokens = [\" \".join(ngram) for ngram in ngrams]\n",
    "        tok_twts.append(tokens)\n",
    "    \n",
    "    dictionary = gensim.corpora.Dictionary(tok_twts)\n",
    "    corpus = [dictionary.doc2bow(tweet) for tweet in tok_twts]\n",
    "    \n",
    "    for k in range(num_topics):\n",
    "        ldamodel = gensim.models.ldamodel.LdaModel(corpus, \n",
    "                                                   iterations=50, \n",
    "                                                   num_topics=k, \n",
    "                                                   id2word=dictionary, \n",
    "                                                   passes=20)\n",
    "        \n",
    "    \n",
    "        cm = CoherenceModel(model=ldamodel, corpus=corpus, coherence='u_mass')\n",
    "        coherences.append(cm.get_coherence())\n",
    "        topic_num.append(k)\n",
    "        \n",
    "    return coherences, topic_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get best topic numbers for each model\n",
    "# Run model with that number of topics\n",
    "    # Keep track of city, state for each model (This is stored in places list)\n",
    "# Extract topics from each model and create tuple (place[i], topic[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#en_stop = set(nltk.corpus.stopwords.words('english'))\n",
    "#tok_twts = []\n",
    "#n = 2\n",
    "#for tweet in tweets['tweet']:\n",
    " #   tokens = nltk.tokenize.word_tokenize(tweet)\n",
    " #   tokens = [token for token in tokens if token not in en_stop]\n",
    "  #  tokens = [token.lower() for token in tokens]\n",
    "  #  ngrams = zip(*[tokens[i:] for i in range(n)])\n",
    "   # tokens = [\" \".join(ngram) for ngram in ngrams]\n",
    "    #tok_twts.append(tokens)\n",
    "    \n",
    "#dictionary = gensim.corpora.Dictionary(tok_twts)\n",
    "#corpus = [dictionary.doc2bow(tweet) for tweet in tok_twts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nazbi\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:160: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, keywords, defaults = inspect.getargspec(kallable)\n"
     ]
    }
   ],
   "source": [
    "#pickle.dump(corpus, open('corpus.pkl', 'wb'))\n",
    "#dictionary.save('dictionary.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nazbi\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:160: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, keywords, defaults = inspect.getargspec(kallable)\n",
      "C:\\Users\\nazbi\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:160: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, keywords, defaults = inspect.getargspec(kallable)\n",
      "C:\\Users\\nazbi\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:160: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, keywords, defaults = inspect.getargspec(kallable)\n"
     ]
    }
   ],
   "source": [
    "#NUM_TOPICS = 12\n",
    "#ldamodel = gensim.models.ldamodel.LdaModel(corpus, iterations=50, num_topics=NUM_TOPICS, id2word=dictionary, passes=20)\n",
    "#ldamodel.save('model.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x = ldamodel.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5617708938970447"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cm = CoherenceModel(model=ldamodel, corpus=corpus, coherence='u_mass')\n",
    "#cm.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
